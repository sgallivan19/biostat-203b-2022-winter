---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 18 @ 11:59PM
output:
  # ioslides_presentation: default
  html_document:
    toc: true
    toc_depth: 4
---

```{r, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

Display machine information:
```{r}
sessionInfo()
```
Load database libraries and the tidyverse frontend:
```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(miceRanger))
```

## Q1. Missing data

Through the Shiny app developed in HW3, we observe abundant missing values in the MIMIC-IV ICU cohort we created. In this question, we use multiple imputation to obtain a data set without missing values.

0. Read following tutorials on the R package miceRanger for imputation: <https://github.com/farrellday/miceRanger>, <https://cran.r-project.org/web/packages/miceRanger/vignettes/miceAlgorithm.html>.

    A more thorough book treatment of the practical imputation strategies is the book [*_Flexible Imputation of Missing Data_*](https://stefvanbuuren.name/fimd/) by Stef van Buuren. 

1. Explain the jargon MCAR, MAR, and MNAR.

**Solution**

MCAR: missing completely at random. Missingness has no relation to variables in the dataset. 

MAR: missing at random. The missing data of variable Y is related to some other completely observed variable X but not related to the observed values of Y itself. 

MNAR: missing not at random. Missingness is specifically related to what is missing. The missing data of variable Y is related to some other completely observed variable X and also related to the observed values of Y itself. 

2. Explain in a couple of sentences how the Multiple Imputation by Chained Equations (MICE) work.

**Solution**

A variable, x, is chosen at random and the other variables are used to predict x's values using a random forest algorithm. The next variable in line then uses the other variables (including the now full with no missing values variable x) to predict its values using a random forest algorithm. This goes on until all variables now have full non-missing data. The process does not stop though. Previously imputed values in a variable are re-imputed by running a random forest prediction algorithm using all of the other full variables. This re-imputation process is iteraterd through each variable. Once through the whole dataset, imputed variable values are re-imputated again! This re-imputation process is done several times, iterating over the full dataset, hence the term "multiple imputation". 

3. Perform a data quality check of the ICU stays data. Discard variables with substantial missingness, say >5000 `NA`s. Replace apparent data entry errors by `NA`s.

**Solution**

```{r}
# read rds data 
icu_cohort <- 
  read_rds("~/biostat-203b-2022-winter/hw3/mimiciv_shiny/icu_cohort.rds")
# parse desired variables for miceranger/prediction model
icu_cohort
icu_cohort1 <- icu_cohort %>% 
  select(
    gender, anchor_age, insurance, language, marital_status, ethnicity, 
    lab50912, lab50882, lab50960, lab50983, lab50893, lab50902, lab51221,
    lab50971, lab51301, lab50931, event220210, lab51301, lab50931, event220210,
    event223761, event220179, event220045, event220181, thirty_day_mort
  )
# examine variables for outliers  and substantial missingness 
summary(icu_cohort1)
colSums(is.na(icu_cohort1))
# replace chart and lab events < 0 with NA 
icu_cohort2 <- icu_cohort1 %>% 
  mutate(
    event223761 = replace(event223761, event223761 < 0, NA),
    event220179 = replace(event220179, event220179 < 0, NA),
    event220045 = replace(event220045, event220045 < 0, NA),
    event220181 = replace(event220181, event220181 < 0, NA)
  )
```

4. Impute missing values by `miceRanger` (request $m=3$ data sets). This step is computational intensive. Make sure to save the imputation results as a file. Hint: Setting `max.depth=10` in the `miceRanger` function may cut some computing time.

**Solution**

```{r}
require(miceRanger)
set.seed(1)
# impute values using miceRanger
seqTime <- system.time(
  icu_cohort_imputed <- miceRanger(
      icu_cohort2
    , m = 3
    , returnModels = FALSE
    , verbose = FALSE
    , max.depth = 10
    
  )
)
icu_cohort_imputed %>%
    write_rds("icu_cohort_imputed.rds")
```

5. Make imputation diagnostic plots and explain what they mean.

**Solution**

```{r}
plotDistributions(icu_cohort_imputed)
```

These models plot the imputed distributions compared to the original distribution for each variable. The red line is the density of the original, nonmissing data. The smaller, black lines are the density of the imputed values in each of the datasets. For those variables where the lines do not match up, it may tell us that our data was not MCAR. 

```{r}
plotCorrelations(icu_cohort_imputed)
```

These plotCorrelations models shows us a boxplot of the correlations between imputed values in every combination of datasets, at each iteration. This helps us know how our values between datasets converged over the iterations.

```{r}
plotModelError(icu_cohort_imputed)
```

Each of these models return the OOB accuracy for classification and r-squared for regression. We can see how these converged as the iterations progress. 

```{r}
plotVarImportance(icu_cohort_imputed)
```

These plots show the variable importance for each imputed variable. The top axis contains the variable that was used to impute the variable on the left axis.

```{r}
plotImputationVariance(icu_cohort_imputed)
```

The imputation variance plots show how “certain” we were of our imputations. This gives us a feel for the variance experienced for each imputed value between the datasets.

6. Choose one of the imputed data sets to be used in Q2. This is **not** a good idea to use just one imputed data set or to average multiple imputed data sets. Explain in a couple of sentences what the correct Multiple Imputation strategy is.

**Solution**

The correct multiple imputation strategy is to conduct analyses on each of the imputed datasets separately and then pool all of the results. 

## Q2. Predicting 30-day mortality

Develop at least two analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression (`glm()` function in base R or keras), (2) logistic regression with lasso penalty (glmnet or keras package), (3) random forest (randomForest package), or (4) neural network (keras package).

1. Partition data into 80% training set and 20% test set. Stratify partitioning according the 30-day mortality status.

```{r}
# extract a dataset from the three imputed datasets
d <- completeData(icu_cohort_imputed)
df <- d$Dataset_1
# partition data into training and test 
# load caret library 
library(caret)
# set seed
set.seed(3456)
# create index for training data 
train_index <- caret::createDataPartition(df$thirty_day_mort, p = .8,
                                          list = F,
                                          times = 1)
# create train and test dfs from indices
df_train <- df[train_index,]
df_test  <- df[-train_index,]
```

2. Train the models using the training set.

**Logistic regression with lasso penalty**
```{r}
#load required library
library(glmnet)
#create covariate matrix and predictor variable as x and y 
x <- model.matrix(thirty_day_mort ~ ., df_train)
y <- df_train$thirty_day_mort
#find optimal value of lambda
#family= binomial => logistic regression, alpha=1 => lasso
cv.out <- cv.glmnet(x, y, alpha=1, family = "binomial", type.measure = "auc" )
#plot result
#plot(cv.out)
#min value of lambda
lambda_min <- cv.out$lambda.min
#best value of lambda
lambda_1se <- cv.out$lambda.1se
#regression coefficients from the model 
coef(cv.out, s = lambda_1se)
```

3. Compare model prediction performance on the test set.

**Logistic regression with lasso penalty test results**
```{r}
#get test data
x_test <- model.matrix(df_test$thirty_day_mort ~ ., df_test)
#predict thirty day mortality 
lasso_prob <- predict(cv.out, newx = x_test, s = lambda_1se, type = "response")
#translate probabilities to predictions
lasso_predict <- ifelse(lasso_prob > .5, "Yes", "No")
#confusion matrix
table(predicted = lasso_predict, observed = df_test$thirty_day_mort)
# accuracy 
cat("Test Accuracy:", mean(lasso_predict == df_test$thirty_day_mort))
```

```{r}
#install and load keras 
library(keras)
install_keras()
```

```{r}
# install and load reticulate 
library(reticulate)
virtualenv_create("r-reticulate")
```

